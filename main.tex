\documentclass[a4paper,twocolumn,10pt]{article}
\usepackage[margin=15mm]{geometry}
\usepackage[hidelinks]{hyperref} % clickable links
\usepackage[fleqn]{amsmath}
\usepackage{amssymb}
\usepackage{enumitem} % control lists
    \setlist{nosep} % make lists more compact
% \usepackage[lists=normal]{savetrees} % extreme

\title{CENG97009 Advanced Process Optimisation 1}
\author{Andreas Richardson}
\date{April 2021}

\begin{document}

\maketitle

% \tableofcontents

\section{Lecture 1}

\subsection{Problem formulation}
\begin{equation}
\begin{array}{cc}
\min_{\boldsymbol{x}, \boldsymbol{y}}     & f(\boldsymbol{x}, \boldsymbol{y}) \\
\text { s.t. }  & \boldsymbol{g}(\boldsymbol{x}, \boldsymbol{y}) \leq \mathbf{0} \\
                & \boldsymbol{h}(\boldsymbol{x}, \boldsymbol{y}) = \mathbf{0} \\
                & \boldsymbol{x} \in X \subset \mathbb{R}^{n} \\
                & \boldsymbol{y} \in\{0,1\}^{q}
\end{array}
\end{equation}
Bound constraints also feature:
\begin{align}
    x-x^{U} &\leq 0 & x^{L}-x &\leq 0
\end{align}

\subsection{Nonlinear optimisation}
\begin{description}
    \item[Degrees of Freedom] $\operatorname{DoF}=\operatorname{dim}(\boldsymbol{x})-\operatorname{dim}(\boldsymbol{h})$
    \item[Feasible region] $F=\{\boldsymbol{x} \in X: \boldsymbol{h}(\boldsymbol{x})=\mathbf{0}, \boldsymbol{g}(\boldsymbol{x}) \leq \mathbf{0}\}$
    \item[Optimal solution] $\boldsymbol{x}^{*} \in F: f\left(\boldsymbol{x}^{*}\right) \leq f(\boldsymbol{x}) \forall \boldsymbol{x} \in F$ 
\end{description}

\subsection{Basic concepts}
\begin{description}
    \item[Global minimum] $f\left(\boldsymbol{x}^{*}\right) \leq f(\boldsymbol{x}) \forall \boldsymbol{x} \in F$ 
    \item[Strong minimum] If inequality can be strict ($<$)
\end{description}

\subsubsection{Convexity}
\begin{equation*}
    f\left(\alpha \boldsymbol{x}_{1}+(1-\alpha) \boldsymbol{x}_{2}\right) \leq \alpha f\left(\boldsymbol{x}_{1}\right)+(1-\alpha) f\left(\boldsymbol{x}_{2}\right), \forall \alpha \in[0,1]
\end{equation*}
Necessary \& sufficient conditions
\begin{gather*}
    f(x) \text { is convex } \Leftrightarrow f^{\prime \prime}(x) \geq 0 \\
    f(x) \text { is strictly convex } \Leftrightarrow f^{\prime \prime}(x)>0\\
    f(\boldsymbol{x}) \text { is strictly convex } \Leftrightarrow \mathbf{z}^{T} H(\boldsymbol{x}) \mathbf{z}>0, \forall \boldsymbol{x}, \forall \boldsymbol{z} \neq \mathbf{0}
\end{gather*}
Multidimensional functions: $\mathbf{z}^{T} H(\boldsymbol{x}) \mathbf{z}>0$ refers to eigenvalues of the Hessian matrix $H$
\begin{equation}
    H\left(x_{1}, x_{2}\right)=\nabla^{2} f\left(x_{1}, x_{2}\right)=\left(\begin{array}{cc}
    \frac{\partial^{2} f}{\partial x_{1}^{2}} & \frac{\partial^{2} f}{\partial x_{1} \partial x_{2}} \\
    \frac{\partial^{2} f}{\partial x_{1} \partial x_{2}} & \frac{\partial^{2} f}{\partial x_{2}^{2}}
    \end{array}\right)
\end{equation}
\begin{equation}
    \boldsymbol{\lambda} = \begin{cases}
        > 0 & \text{+ve definite} \\
        \geq 0 & \text{+ve semi-definite} \\
        \leq 0 & \text{-ve semi-definite} \\
        < 0 & \text{-ve definite} \\
        \text{else} & \text{indefinite}
    \end{cases}
    \begin{array}{l}
        \left.\begin{array}{l}\mathstrut\\\mathstrut\end{array}\right\}\quad\text{Convex}\\
        \left.\begin{array}{l}\mathstrut\\\mathstrut\end{array}\right\}\quad\text{Nonconvex}\\
        \mathstrut
    \end{array}
\end{equation}
Sets/regions may also be convex (s.43)
If the objective function and feasible region are both convex, the problem is convex and has a unique minimum.
\subsubsection{Optimisation}
Neseccary and sufficient conditions:
\begin{description}
    \item[Stationary point] (min/max/saddle) $\nabla f\left(x^{*}\right)=0$
    \item[Strong local minimum] $\boldsymbol{x}^{T} H\left(\boldsymbol{x}^{*}\right) \boldsymbol{x}>0$ (weak: $\geq$) 
\end{description}

\section{Lecture 2}
\subsection{KKT optimality conditions}
Lagrange function
\begin{equation}
    \mathcal{L}\left(\boldsymbol{x}, \boldsymbol{\lambda}, \boldsymbol{\mu}\right)= f\left(\boldsymbol{x}\right)+\boldsymbol{\lambda}^{T} \boldsymbol{h}\left(\boldsymbol{x}\right)+\boldsymbol{\mu}^{T} \boldsymbol{g}\left(\boldsymbol{x}\right)
\end{equation}
Necessary conditions
\begin{align}
    \nabla_{\boldsymbol{x}} \mathcal{L}\left(\boldsymbol{x}^{*}, \boldsymbol{\lambda}^{*}, \boldsymbol{\mu}^{*}\right)=\mathbf{0} \\
    \boldsymbol{h}(\boldsymbol{x})=\mathbf{0} \\
    \boldsymbol{\mu}^{* T} \boldsymbol{g}\left(\boldsymbol{x}^{*}\right)=\mathbf{0} \\
    \boldsymbol{\mu}^{*} \geq \mathbf{0}
\end{align}
Also sufficient conditions (more complicated, s.26).
Use the iterative active set strategy (s.28).

\section{Lecture 3}
\subsection{Propositional logic}
\begin{tabular}{@{}ll@{}}
    Symbol      & Meaning   \\
    $\vee$      & OR        \\
    $\oplus$    & XOR       \\
    $\wedge$    & AND       \\
    $\neg$      & NOT       
\end{tabular}
\subsection{Algebraic equations}
\begin{enumerate}
    \item Define binary variable $y_i$ for each clause $P_i$
    \item Transform logic expressions to conjunctive normal form ($Q_1 \wedge Q_2 \wedge \ldots \wedge Q_n$)
        \begin{itemize}
            \item Replace implication ($P_{1} \Rightarrow P_{2} \equiv \neg P_1 \vee P_2$)
            \item Apply de Morgan's theorem
                \begin{equation}
                    \begin{array}{l}
                    \neg\left(P_{1} \wedge P_{2}\right) \Leftrightarrow\left(\neg P_{1} \vee \neg P_{2}\right) \\
                    \neg\left(P_{1} \vee P_{2}\right) \Leftrightarrow\left(\neg P_{1} \wedge \neg P_{2}\right)
                    \end{array}
                \end{equation}
            \item Factor out OR over AND
                \begin{equation}
                    \left(P_{1} \wedge P_{2}\right) \vee P_{3} \Leftrightarrow \underbrace{\left(P_{1} \vee P_{3}\right)}_{Q_{1}} \wedge \underbrace{\left(P_{2} \vee P_{3}\right)}_{Q_{2}}
                \end{equation}
        \end{itemize}
\end{enumerate}
Big-M constraints allow either/or and discontinuous expressions.
Can use a series of binary variables to represent integers.
\subsection{Integer cuts}
To remove combination $\tilde{y}$, set $Z=\left\{i: \tilde{y}_{i}=0\right\}$ and $N Z=\left\{i: \tilde{y}_{i}=1\right\}$ then
\begin{equation}
    \sum_{i \in N Z} y_{i}-\sum_{i \in Z} y_{i} \leq|N Z|-1
\end{equation}
\subsection{(MI)LP relaxation}
Remove integrality on $\boldsymbol{y}$; MILP becomes LP. Solution lower or equal to that of original MILP.
\subsection{Branch-and-bound}
Basic idea: fix some $y_k$ and solve relaxed subproblem $P_j$.
\begin{description}
    \item[Branching strategy] commonly most-fractional variable
    \item[Node selection] newest/best bound (depth/breadth)
\end{description}

\section{Lecture 4}
\subsection{Solving MINLPs}
\begin{description}
    \item[Convexity] for a fixed $\boldsymbol{y}$
\end{description}
Use same branch-and-bound as for MILP; relaxation @ nodes is now NLP. Primal/master problem setup w/ 2 methods
\subsection{Generalised benders decomposition (GBD)}
Key feature: deal with $\boldsymbol{x}$ and $\boldsymbol{y}$ separately. Iterative refinement. Primal problem $P^K$ provides UB; master problem $M^K$ provides LB.
\subsection{Outer approximation (OA)}
Same iterative process as GBD. Master problem different: constructed from sum of linearisations of problem at all previous iterations $k$. Graphically represents a series of linear approximations to the function.
Comparison w/ OA: larger $M^K$, LB as good or better, fewer iterations.

\section{Lecture 5}

Not examinable.

\section{Lecture 6}
\subsection{Global optimisation}
Different methods exist
\begin{description}
    \item[Incomplete] explore lots of space, but don't necessarily find GO
    \item[Asymptotically complete] explores infinite space given infinite time
    \item[Complete] finds GO (to a tolerance) within finite time
    \item[Rigorous] adds in error control
\end{description}
Pros/cons are fairly obvious
\subsection{Convex relaxations}
$\breve{f}(x) \leq f(x), \forall x \in X$ and $\breve{f}(x)$ is convex.
Convex relaxation of NLP provides LB on solution: $\underline{f}^{*} \leq f^{*}$, whereas any \textit{local} solution of the original (nonconvex) NLP provides an UB.
Apply branch-and-bound to find the actual global optimum.

Various methods exist to find convex relaxations:
\begin{description}
    \item[Secant underestimator]
        \begin{equation}
            \breve{f}(x)=f\left(x^{L}\right)+\frac{f\left(x^{U}\right)-f\left(x^{L}\right)}{x^{U}-x^{L}}\left(x-x^{L}\right)
        \end{equation}
    \item[McCormick] for bilinear terms
        \begin{gather*}
            \left.\begin{array}{l}
                (x-x^L)(y-y^L) \geq 0 \\
                (x^U-x)(y^U-y) \geq 0        
            \end{array} \right\} \text{underestimators} \\
            \left.\begin{array}{l}
                (x-x^L)(y^U-y) \geq 0 \\
                (x^U-x)(y-y^L) \geq 0
            \end{array} \right\} \text{overestimators}
        \end{gather*}
    \item[$\alpha$BB] for continous, twice-differentiable functions
        \begin{gather}
            L_{f}(\boldsymbol{x})=f(\boldsymbol{x})+\alpha\left(\boldsymbol{x}-\boldsymbol{x}^{L}\right)^{T}\left(\boldsymbol{x}-\boldsymbol{x}^{U}\right) \\
            \alpha \geq \max \left\{0 ;-\frac{1}{2} \min _{x \in X} \lambda_{\min }\left(H_{f}(\boldsymbol{x})\right)\right\}
        \end{gather}
        If $\alpha$ cannot be calculated analytically, use interval arithmetic and scaled Gerschgorin theorem. Can also use SGT to calculate non-uniform shift $\alpha_i$.
\end{description}

\section{Lecture 7}
Process uncertainties:
\begin{description}
    \item[Internal] e.g. rate constant, fouling, efficiency
    \item[External] e.g. feed composition, ambient temperature
\end{description}
\subsection{Process flexibility}
Definition: capability to maintain feasible operation under changing conditions.
Symbols: $\boldsymbol{\theta}$ - uncertain parameters, $\boldsymbol{d}$ - design variables, $\boldsymbol{z}$ - control variables, $\boldsymbol{x}$ - state variables.
Start with a full process model and reduce it to focus on $\boldsymbol{\theta}$, $\boldsymbol{z}$.
\subsection{Flexibility analysis}
Given a design $\boldsymbol{d}$ and $\boldsymbol{\theta} \in [\boldsymbol{\theta}^L,\boldsymbol{\theta}^U]$, with $\boldsymbol{z}$ allowed to vary:
\begin{description}
    \item[Flexibility test] is the design feasible across the \textit{entire} range? (Yes/No).
        Minimise the maximum violation of the constraints using control:
        \begin{gather*}
            \min_{\boldsymbol{z}} \max\left\{\boldsymbol{f}\left(\boldsymbol{z}, \boldsymbol{\theta}\right)\right\} \\
            \psi(\boldsymbol{\theta}) = \begin{array}[t]{rc} \min _{\boldsymbol{z},u} & u \\
                \text {s.t.} & u \geq \boldsymbol{f}\left(\boldsymbol{z},\boldsymbol{\theta}\right)
            \end{array}
        \end{gather*}
        Thus we seek to find the region of feasible operation $R = \{\boldsymbol{\theta} | \psi(\boldsymbol{\theta}) \leq 0\}$.
        If the inequalities are linear, we need only evaluate $\psi(\boldsymbol{\theta})$ at the vertices $\boldsymbol{\theta} \in \{\boldsymbol{\theta}^L,\boldsymbol{\theta}^U\}$.
    \item[Flexibility index] for which \textit{proportion} of the range is the design feasible?
        \begin{equation*}
            \delta^k =\begin{array}[t]{rc} \max_{\delta,\boldsymbol{z}} & \delta \\
            \text {s.t.} & \boldsymbol{f}\left(\boldsymbol{z},\boldsymbol{\theta}\right) \leq 0 \\
            & \boldsymbol{\theta} = \boldsymbol{\theta}^N \pm^{(k)} \delta\times\Delta\boldsymbol{\theta}
            \end{array}
        \end{equation*}
        Evaluate at all vertices $k$; pick $\delta = \min_{k} \delta^k$
\end{description}
\subsection{Design for flexibility}
Looking for the best design $\boldsymbol{d}$
\begin{description}
    \item[Multiperiod optimisation] select periods $i$ with weightings $W_i$ and cost functions $\Phi_i$
        \begin{equation*}
            \begin{array}{rc}
                \min _{\boldsymbol{d}, \mathbf{z}_{1}, \ldots, \mathbf{z}_{N}} & c(\boldsymbol{d})+\sum_{i=1}^{N} W_{i} \Phi_{i}\left(\boldsymbol{d}, \mathbf{z}_{i}, \boldsymbol{\theta}_{i}\right) \\
                \text{s.t. }& \boldsymbol{f}\left(\boldsymbol{d}, \mathbf{z}_{\boldsymbol{i}}, \boldsymbol{\theta}_{\boldsymbol{i}}\right) \leq \mathbf{0}, i=1, \ldots, N \\
                & \boldsymbol{g}(\boldsymbol{d}) \leq \mathbf{0}
            \end{array}
        \end{equation*} 
    \item[Design under uncertainty] Pick several sets of $\boldsymbol{\theta}$ and assign weights. Do multiperiod optimisation. Text flexibility. If fails, add any critical points as an additional period.
\end{description}

\end{document}
